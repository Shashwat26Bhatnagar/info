{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0IPx0BWctLA"
      },
      "outputs": [],
      "source": [
        "#in the name of GOD#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLq7ivfrcs9O",
        "outputId": "7f14d48d-475a-4e44-bc53-4b172ebc9dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Informer2020'...\n",
            "remote: Enumerating objects: 649, done.\u001b[K\n",
            "remote: Counting objects: 100% (295/295), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 649 (delta 245), reused 188 (delta 188), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (649/649), 6.50 MiB | 13.18 MiB/s, done.\n",
            "Resolving deltas: 100% (382/382), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cloner174/Informer2020.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDS2-pFMFZCk",
        "outputId": "e2a131fa-3a5e-4209-92cc-108968bbfbf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Informer2020\n"
          ]
        }
      ],
      "source": [
        "%cd 'Informer2020'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnrQ1p799eBy",
        "outputId": "a4c09010-3421-463f-953f-d46eb0fea20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is The Enhanced Version of Orginal code , Written in 2024 \n",
            "Args in experiment:\n",
            "{'root_path': '/content/Informer2020/input/', 'data_path': 'data.csv', 'model': 'informer', 'data': 'custom', 'features': 'MS', 'target': 'Close', 'freq': 'b', 'checkpoints': './informer_checkpint', 'seq_len': 30, 'label_len': 1, 'pred_len': 1, 'enc_in': 6, 'dec_in': 6, 'c_out': 1, 'factor': 1, 'd_model': 512, 'n_heads': 16, 'e_layers': 8, 'd_layers': 8, 'd_ff': 2048, 's_layers': [3, 2, 1], 'dropout': 0.01, 'attn': 'full', 'embed': 'learned', 'activation': 'ReLU6', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 16, 'learning_rate': 5e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 2, 'itr': 1, 'train_epochs': 10, 'patience': 5, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'do_predict': None, 'test_size': 0.2, 'kind_of_optim': 'Adam', 'inverse': False, 'scale': True, 'kind_of_scaler': 'MinMax', 'take_data_instead_of_reading': False, 'shuffle_for_test': False, 'shuffle_for_pred': False, 'shuffle_for_train': True, 'criter': 'MAE', 'detail_freq': 'b'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from utils.tools import dotdict\n",
        "\n",
        "from exp.exp_informer import Exp_Informer\n",
        "\n",
        "args = dotdict()\n",
        "\n",
        "\n",
        "\n",
        "args.root_path = '/content/Informer2020/input/'\n",
        "\n",
        "args.data_path = 'data.csv'\n",
        "\n",
        "args.model = 'informer'                      #  options: [ informer, informerstack-NOTSUREYET!-, informerlight(TBD)-NOTSUREYET!-]\n",
        "\n",
        "args.data = 'custom'\n",
        "\n",
        "args.features = 'MS'\n",
        "\n",
        "args.target = 'Close'\n",
        "\n",
        "args.freq = 'b'\n",
        "\n",
        "args.checkpoints = './informer_checkpint' # location of model checkpoints\n",
        "\n",
        "args.seq_len =  1*5*6\n",
        "\n",
        "args.label_len = 1*1\n",
        "args.pred_len = 1*1\n",
        "\n",
        "args.enc_in  =  6         \t\t   # Encoder input size\n",
        "args.dec_in  =  6          \t\t  # Decoder input size\n",
        "args.c_out   =  1            \t\t # Output size\n",
        "\n",
        "args.factor  =  1            \t\t  # Probsparse attn factor\n",
        "\n",
        "args.d_model = 512            \t\t # Dimension of model\n",
        "args.n_heads = 16            \t\t   # 16خوب\n",
        "args.e_layers = 8          \t\t # num of encoder layers\n",
        "args.d_layers = 8           \t\t# num of decoder layers\n",
        "args.d_ff    =  2048         \t\t# dimension of fcn in model\n",
        "args.s_layers = '3,2,1'\t\t\t#help='num of stack encoder layers'\n",
        "\n",
        "args.dropout  =  0.01         # dropout\n",
        "\n",
        "args.attn = 'full'                  # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'learned'              # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'ReLU6'            # activation\n",
        "\n",
        "args.distil = True                      # whether to use distilling in encoder\n",
        "args.output_attention = False           # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "\n",
        "args.padding = 0\n",
        "\n",
        "args.batch_size = 16\n",
        "args.learning_rate = 0.00005\n",
        "\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "\n",
        "args.use_amp = False                    # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 2\n",
        "\n",
        "args.itr = 1\n",
        "\n",
        "args.train_epochs = 10\n",
        "\n",
        "args.patience = 5\n",
        "\n",
        "args.des = 'exp'\t\t\t#default='test',help='exp description'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "\n",
        "args.gpu = 0\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n",
        "\n",
        "args.do_predict = None\t\t\t# help='whether to predict unseen future dat\n",
        "\n",
        "\n",
        "\n",
        "#    #    #    new#    #\n",
        "\n",
        "args.test_size = 0.2\n",
        "\n",
        "args.kind_of_optim = 'Adam'               # optimizer to use,options:AdamW|SparseAdam|RMSprop|AdagradRAdam|NAdam|LBFGS|AdamaxAdadelta|Adam |SGD | ASGD\n",
        "\n",
        "args.inverse=False\n",
        "\n",
        "args.scale=True#*****#\n",
        "\n",
        "args.kind_of_scaler = 'MinMax'#*****#                  #   Standard   or   MinMax\n",
        "\n",
        "args.take_data_instead_of_reading = False#*****#            # Defualt to False.. if it is True, you should provide direct_data!\n",
        "\n",
        "args.shuffle_for_test  =  False\n",
        "args.shuffle_for_pred  =  False\n",
        "args.shuffle_for_train  =  True\n",
        "\n",
        "args.criter =  'mse'       # lose function options: WMAPE|SMAPE|MAE|RMSE|QuantileLoss|HuberLoss|PinballLoss\n",
        "\n",
        "#    #    #    new#    #\n",
        "\n",
        "\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ','').split(',')]\n",
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]\n",
        "\n",
        "#if args.use_gpu and args.use_multi_gpu:\n",
        "#    args.devices = args.devices.replace(' ','')\n",
        "#    device_ids = args.devices.split(',')\n",
        "#    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "#    args.gpu = args.device_ids[0]\n",
        "\n",
        "\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "Exp = Exp_Informer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJwLy0T5Fs9W",
        "outputId": "317bd519-1139-4b47-d356-befe89464561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : informer_custom_ftMS_sl30_ll1_pl1_dm512_nh16_el8_dl8_df2048_atfull_fc1_eblearned_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 2553\n",
            "val 370\n",
            "test 738\n",
            "\titers: 100, epoch: 1 | loss: 0.1318520\n",
            "\tspeed: 0.1530s/iter; left time: 228.1247s\n",
            "Epoch: 1 cost time: 18.40688395500183\n",
            "Epoch: 1, Steps: 159 | Train Loss: 0.2494314 Vali Loss: 0.2694891 Test Loss: 0.1663771\n",
            "Validation loss decreased (inf --> 0.269489).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 2 | loss: 0.0891787\n",
            "\tspeed: 0.1945s/iter; left time: 259.0173s\n",
            "Epoch: 2 cost time: 15.436031818389893\n",
            "Epoch: 2, Steps: 159 | Train Loss: 0.0919340 Vali Loss: 0.1581803 Test Loss: 0.1385274\n",
            "Validation loss decreased (0.269489 --> 0.158180).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.1107428\n",
            "\tspeed: 0.1912s/iter; left time: 224.2466s\n",
            "Epoch: 3 cost time: 16.902504444122314\n",
            "Epoch: 3, Steps: 159 | Train Loss: 0.0608394 Vali Loss: 0.1632368 Test Loss: 0.0796496\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.0304902\n",
            "\tspeed: 0.2025s/iter; left time: 205.3838s\n",
            "Epoch: 4 cost time: 16.406946420669556\n",
            "Epoch: 4, Steps: 159 | Train Loss: 0.0457320 Vali Loss: 0.1398707 Test Loss: 0.0574001\n",
            "Validation loss decreased (0.158180 --> 0.139871).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 5 | loss: 0.0411585\n",
            "\tspeed: 0.1917s/iter; left time: 163.8752s\n",
            "Epoch: 5 cost time: 16.29410982131958\n",
            "Epoch: 5, Steps: 159 | Train Loss: 0.0360246 Vali Loss: 0.0866550 Test Loss: 0.0899858\n",
            "Validation loss decreased (0.139871 --> 0.086655).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0364356\n",
            "\tspeed: 0.1901s/iter; left time: 132.3343s\n",
            "Epoch: 6 cost time: 15.44459319114685\n",
            "Epoch: 6, Steps: 159 | Train Loss: 0.0325595 Vali Loss: 0.0856369 Test Loss: 0.0435192\n",
            "Validation loss decreased (0.086655 --> 0.085637).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.0323419\n",
            "\tspeed: 0.2414s/iter; left time: 129.6533s\n",
            "Epoch: 7 cost time: 22.708102464675903\n",
            "Epoch: 7, Steps: 159 | Train Loss: 0.0279119 Vali Loss: 0.0906180 Test Loss: 0.0411954\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 8 | loss: 0.0224858\n",
            "\tspeed: 0.2168s/iter; left time: 81.9575s\n",
            "Epoch: 8 cost time: 16.04071855545044\n",
            "Epoch: 8, Steps: 159 | Train Loss: 0.0260189 Vali Loss: 0.0887450 Test Loss: 0.0403310\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Updating learning rate to 3.90625e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.0396714\n",
            "\tspeed: 0.1884s/iter; left time: 41.2581s\n",
            "Epoch: 9 cost time: 17.252419471740723\n",
            "Epoch: 9, Steps: 159 | Train Loss: 0.0259775 Vali Loss: 0.0904356 Test Loss: 0.0387326\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Updating learning rate to 1.953125e-07\n",
            "\titers: 100, epoch: 10 | loss: 0.0200477\n",
            "\tspeed: 0.2085s/iter; left time: 12.5074s\n",
            "Epoch: 10 cost time: 16.607531547546387\n",
            "Epoch: 10, Steps: 159 | Train Loss: 0.0250808 Vali Loss: 0.0838550 Test Loss: 0.0373089\n",
            "Validation loss decreased (0.085637 --> 0.083855).  Saving model ...\n",
            "Updating learning rate to 9.765625e-08\n",
            ">>>>>>>testing : informer_custom_ftMS_sl30_ll1_pl1_dm512_nh16_el8_dl8_df2048_atfull_fc1_eblearned_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 738\n",
            "test shape: (46, 16, 1, 1) (46, 16, 1, 1)\n",
            "test shape: (736, 1, 1) (736, 1, 1)\n",
            "mse:0.0031688674353063107, mae:0.03730888292193413\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n",
        "                args.seq_len, args.label_len, args.pred_len,\n",
        "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor,\n",
        "                args.embed, args.distil, args.mix, args.des, ii)\n",
        "\n",
        "    exp = Exp(args) # set experiments\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "\n",
        "    if args.do_predict:\n",
        "        print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "        exp.predict(setting, True)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcl9kc4VA6Oj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCIEcMCpZC58"
      },
      "outputs": [],
      "source": [
        "#exp.train_losses\n",
        "#exp.test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oTAKN3idKOCY"
      },
      "outputs": [],
      "source": [
        "trues = np.load('/content/Informer2020/results/informer_custom_ftMS_sl30_ll1_pl1_dm512_nh16_el8_dl8_df2048_atfull_fc1_eblearned_dtTrue_mxTrue_exp_0/true.npy')\n",
        "preds = np.load('/content/Informer2020/results/informer_custom_ftMS_sl30_ll1_pl1_dm512_nh16_el8_dl8_df2048_atfull_fc1_eblearned_dtTrue_mxTrue_exp_0/pred.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7lDoBFRBW_0",
        "outputId": "7581ebf4-3f3b-4c02-c94b-0027aca75788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     True Scaled  Predict Scaled   True   Pred\n",
            "0       1.374513        1.148601  65510  55129\n",
            "1       1.428721        1.136797  68001  54586\n",
            "2       1.526843        1.120755  72510  53849\n",
            "3       0.680543        1.121818  33620  53898\n",
            "4       0.717102        0.734984  35300  36122\n",
            "..           ...             ...    ...    ...\n",
            "731     0.247274        0.266948  13710  14614\n",
            "732     0.260114        0.247869  14300  13737\n",
            "733     0.267512        0.288806  14640  15619\n",
            "734     0.265554        0.283655  14550  15382\n",
            "735     0.258155        0.277131  14210  15082\n",
            "\n",
            "[736 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "loaded_scaler = joblib.load('input/scaler.pkl')\n",
        "\n",
        "pred_inversed = loaded_scaler.inverse_transform(preds.reshape(-1,1))\n",
        "\n",
        "true_inversed = loaded_scaler.inverse_transform(trues.reshape(-1,1))\n",
        "\n",
        "true_inversed = [round(any_) for any_ in true_inversed.reshape(-1)]\n",
        "pred_inversed = [round(any_) for any_ in pred_inversed.reshape(-1)]\n",
        "\n",
        "ts = pd.Series(trues.reshape(-1))\n",
        "ps = pd.Series(preds.reshape(-1))\n",
        "t = pd.Series(true_inversed)\n",
        "p = pd.Series(pred_inversed)\n",
        "result = pd.concat([ts,ps, t, p], axis=1)\n",
        "result = result.set_axis(['True Scaled', 'Predict Scaled', 'True', 'Pred'], axis=1)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
